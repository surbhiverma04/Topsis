# Topsis
This assignment focuses on evaluating the performance of five pre-trained text conversation models in the field of natural language processing. The selected models include Facebook's BlenderBot-400M-distill, GPT-2, T5-base, Microsoft's DialoGPT-medium, and RoBERTa-base. The assessment is conducted based on various key parameters, namely BLEU (Bilingual Evaluation Understudy), Rouge-L (Longest Common Subsequence-based metric), Coherence Score, Rouge-1 (Overlap-based metric), and Response Length.

The Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) will be employed to rank and compare these models against each other for each parameter. TOPSIS is a multi-criteria decision-making method that aids in identifying the best-performing model by considering both the closeness to the ideal solution and the remoteness from the negative ideal solution.

Through this assignment, we aim to provide insights into the strengths and weaknesses of each model across different evaluation criteria, offering a comprehensive understanding of their capabilities in the context of text-based conversation tasks.
